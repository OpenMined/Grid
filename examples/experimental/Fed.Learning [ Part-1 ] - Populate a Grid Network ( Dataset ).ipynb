{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Populate remote grid nodes with labeled tensors </h1>\n",
    "In this notebook, we will populate our grid nodes with labeled data so that it will be used later by people interested in train models.\n",
    "\n",
    "**NOTE:** At the time of running this notebook, we were running the grid components in background mode.  \n",
    "\n",
    "Components:\n",
    " - Grid Gateway(http://localhost:8080)\n",
    " - Grid Node Bob (http://localhost:3000)\n",
    " - Grid Node Alice (http://localhost:3001)\n",
    " - Grid Node Bill (http://localhost:3002)\n",
    "\n",
    "This notebook was made based on <a href=\"https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2010%20-%20Federated%20Learning%20with%20Secure%20Aggregation.ipynb\">Part 10: Federated Learning with Encrypted Gradient Aggregation</a> tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import dependencies</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorflow-1.14.0-py3.7-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorflow-1.14.0-py3.7-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorflow-1.14.0-py3.7-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorflow-1.14.0-py3.7-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorflow-1.14.0-py3.7-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorflow-1.14.0-py3.7-linux-x86_64.egg/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorboard-1.14.0-py3.7.egg/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorboard-1.14.0-py3.7.egg/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorboard-1.14.0-py3.7.egg/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorboard-1.14.0-py3.7.egg/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorboard-1.14.0-py3.7.egg/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tensorboard-1.14.0-py3.7.egg/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tf_encrypted-0.5.9-py3.7-linux-x86_64.egg/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so', error was \"/home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tf_encrypted-0.5.9-py3.7-linux-x86_64.egg/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so: undefined symbol: _ZN10tensorflow12OpDefBuilder4AttrESs\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ionesio/workspace/dev/vev/lib/python3.7/site-packages/tf_encrypted-0.5.9-py3.7-linux-x86_64.egg/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import grid as gr\n",
    "import syft as sy\n",
    "import torch\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setup config</h2>\n",
    "Init hook, connect with grid nodes, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# Connect directly to grid nodes\n",
    "nodes = [\"ws://localhost:3000/\",\n",
    "         \"ws://localhost:3001/\",\n",
    "         \"ws://localhost:3002/\" ]\n",
    "\n",
    "compute_nodes = []\n",
    "for node in nodes:\n",
    "    compute_nodes.append( gr.WebsocketGridClient(hook, node) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load dataset</h2>\n",
    "Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "with open('../dataset/boston_housing.pickle','rb') as f:\n",
    "    ((X, y), (X_test, y_test)) = pickle.load(f)\n",
    "\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "\n",
    "# preprocessing\n",
    "mean = X.mean(0, keepdim=True)\n",
    "dev = X.std(0, keepdim=True)\n",
    "mean[:, 3] = 0. # the feature at column 3 is binary,\n",
    "dev[:, 3] = 1.  # so I'd rather not standardize it\n",
    "X = (X - mean) / dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Split dataset </h2>\n",
    "We will split our dataset to send to nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = torch.split(X, int(len(X) / len(compute_nodes)), dim=0 ) #tuple of chunks (dataset / number of nodes)\n",
    "labels = torch.split(y, int(len(X) / len(compute_nodes)), dim=0 )  #tuple of chunks (labels / number of nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tagging tensors</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_x = []\n",
    "tag_y = []\n",
    "\n",
    "for i in range(len(compute_nodes)):\n",
    "    tag_x.append(datasets[i].tag(\"#X\", \"#boston\", \"#housing\").describe(\"The input datapoints to the boston housing dataset.\"))\n",
    "    tag_y.append(labels[i].tag(\"#Y\", \"#boston\", \"#housing\").describe(\"Boston Housing labels\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sending our tensors to grid nodes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For some reason, there is strange behavior when trying to send within a loop.\n",
    "# Ex : tag_x[i].send(compute_nodes[i])\n",
    "# When resolved, this should be updated.\n",
    "\n",
    "shared_x1 = tag_x[0].send(compute_nodes[0], garbage_collect_data=False) # First chunk of dataset to Bob\n",
    "shared_x2 = tag_x[1].send(compute_nodes[1], garbage_collect_data=False) # Second chunk of dataset to Alice\n",
    "shared_x3 = tag_x[2].send(compute_nodes[2], garbage_collect_data=False) # Third chunk of dataset to Bill\n",
    "\n",
    "shared_y1 = tag_y[0].send(compute_nodes[0], garbage_collect_data=False) # First chunk of labels to Bob\n",
    "shared_y2 = tag_y[1].send(compute_nodes[1], garbage_collect_data=False) # Second chunk of labels to Alice\n",
    "shared_y3 = tag_y[2].send(compute_nodes[2], garbage_collect_data=False) # Third chunk of labels to Bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor pointers:  (Wrapper)>[PointerTensor | me:71379891214 -> Bob:80786423983]\n",
      "\tTags: #housing #boston #X \n",
      "\tShape: torch.Size([134, 13])\n",
      "\tDescription: The input datapoints to the boston housing dataset.... (Wrapper)>[PointerTensor | me:84021449540 -> Alice:18146958968]\n",
      "\tTags: #housing #boston #X \n",
      "\tShape: torch.Size([134, 13])\n",
      "\tDescription: The input datapoints to the boston housing dataset.... (Wrapper)>[PointerTensor | me:97004127043 -> Bill:9562088539]\n",
      "\tTags: #housing #boston #X \n",
      "\tShape: torch.Size([134, 13])\n",
      "\tDescription: The input datapoints to the boston housing dataset....\n",
      "Y tensor pointers:  (Wrapper)>[PointerTensor | me:21964710209 -> Bob:81448698219]\n",
      "\tTags: #housing #boston #Y \n",
      "\tShape: torch.Size([134])\n",
      "\tDescription: Boston Housing labels... (Wrapper)>[PointerTensor | me:51075760450 -> Alice:25553850079]\n",
      "\tTags: #housing #boston #Y \n",
      "\tShape: torch.Size([134])\n",
      "\tDescription: Boston Housing labels... (Wrapper)>[PointerTensor | me:381250237 -> Bill:65382525089]\n",
      "\tTags: #housing #boston #Y \n",
      "\tShape: torch.Size([134])\n",
      "\tDescription: Boston Housing labels...\n"
     ]
    }
   ],
   "source": [
    "print(\"X tensor pointers: \", shared_x1, shared_x2, shared_x3)\n",
    "print(\"Y tensor pointers: \", shared_y1, shared_y2, shared_y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Disconnect nodes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(compute_nodes)):\n",
    "    compute_nodes[i].close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
