{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting models on Grid\n",
    "\n",
    "Grid offers both: Machine Learning as a Service and Encrypted Machine Learning as a service. In this series of tutorials we show how you can serve and query models on Grid.\n",
    "\n",
    "This option consists of:\n",
    "\n",
    "**Owner**\n",
    "\n",
    "1. Owner has a model\n",
    "\n",
    "```python\n",
    "model = Plan()\n",
    "model.build(data)\n",
    "```\n",
    "\n",
    "2. Owner shares the model and sends the model to alice in an encrypted fashion\n",
    "\n",
    "```python\n",
    "plan.fix_precision().share(bob, charlie, crypto_provider=dan).send(alice)\n",
    "```\n",
    "\n",
    "**User**\n",
    "\n",
    "1. User fetch the plan (this means they have the state locally as pointers to alice) but they can fetch a plan only once, which means only one user can run inference.\n",
    "\n",
    "This limitation could be turned into a feature if we consider that in the future we may ask for authentication for a user to have access to a model. So the owner could build the model, share it and send to a remote worker (here alice).\n",
    "\n",
    "Then the owner could tell the user \"Hey here's your token, now you have access to the model, you now have access to a encrypted version of my model, but hey, don't lose this model copy, okay? If you lose it you'll have to ask for a new token.\"\n",
    "\n",
    "```\n",
    "# Fetch plan\n",
    "fetched_plan = plan.owner.fetch_plan(plan.id, alice)\n",
    "```\n",
    "\n",
    "2. User shares their data with the same workers\n",
    "\n",
    "```\n",
    "x = th.tensor([-1.0])\n",
    "x_sh = data.fix_precision().share(bob, charlie, crypto_provider=dan)\n",
    "```\n",
    "\n",
    "3. User can run inference using this model copy\n",
    "\n",
    "\n",
    "```\n",
    "decrypted = fetched_plan(x_sh).get().float_prec()\n",
    "```\n",
    "\n",
    "A few notes:\n",
    "\n",
    "- No one knows the model except the model owner (yay!!!)\n",
    "- The model is secure because we only have access to pointers not the actual weights\n",
    "- The user has access to the readable_plan which means the user can figure out the model architecture but not the weight values\n",
    "\n",
    "\n",
    "## 3.2 Host and query an encrypted model\n",
    "### Fetch can be done only once\n",
    "\n",
    "In the previous tutorial we served a CNN for classifying images with different 2 types of skin deseases: benign keratosis and melanoma (type of skin cancer). In this tutorial we show how to serve this model on a **encrypted way** on Grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "import helper\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "# Connect nodes to each other\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marianne/PySyft/syft/frameworks/torch/hook/hook.py:483: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n"
     ]
    }
   ],
   "source": [
    "df = helper.read_skin_cancer_dataset()\n",
    "train_df, valid_df, test_df = helper.split_data(df)\n",
    "\n",
    "# These values are from Part 1.\n",
    "input_size = 32\n",
    "train_mean, train_std = (th.tensor([0.6979, 0.5445, 0.5735]), th.tensor([0.0959, 0.1187, 0.1365]))\n",
    "\n",
    "# Create a test dataloader\n",
    "test_set = helper.Dataset(test_df, transform=helper.transform(input_size, train_mean, train_std))\n",
    "test_generator = th.utils.data.DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "\n",
    "# Get a data sample and a target\n",
    "data, target = next(iter(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a model ready to be served and encrypted\n",
    "\n",
    "In order to serve the model it needs to be serializable. A Plan is intended to store a sequence of torch operations, just like a function, but it allows to send this sequence of operations to remote workers and to keep a reference to it. You can learn more about plans in [Syft's tutorials](https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/Part%2008%20-%20Introduction%20to%20Plans.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "\n",
    "Let's load the model we just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = helper.make_model(is_plan=True)\n",
    "# model.load_state_dict(th.load(\"binary-skin-cancer-detection-model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d315bfe709ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "helper.test(model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Net Net id:convnet owner:me location:Alice built>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fix_precision().share(bob, charlie, crypto_provider=dan).send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "def restart_kernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "    \n",
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "import helper\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "# Connect nodes to each other\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marianne/PySyft/syft/frameworks/torch/hook/hook.py:483: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df = helper.read_skin_cancer_dataset()\n",
    "train_df, valid_df, test_df = helper.split_data(df)\n",
    "\n",
    "# These values are from Part 1.\n",
    "input_size = 32\n",
    "train_mean, train_std = (th.tensor([0.6979, 0.5445, 0.5735]), th.tensor([0.0959, 0.1187, 0.1365]))\n",
    "\n",
    "# Create a test dataloader\n",
    "test_set = helper.Dataset(test_df, transform=helper.transform(input_size, train_mean, train_std))\n",
    "test_generator = th.utils.data.DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "\n",
    "# Get a data sample and a target\n",
    "data, target = next(iter(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sh = data.fix_precision().share(bob, charlie, crypto_provider=dan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a copy of the private model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch plan\n",
    "fetched_plan = me.fetch_plan(\"convnet\", alice, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run encrypted inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0680, 0.0120]])\n",
      "CPU times: user 4min 1s, sys: 1min 31s, total: 5min 33s\n",
      "Wall time: 5min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(fetched_plan(x_sh).get().float_prec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "## Star PySyft on GitHub\n",
    "The easiest way to help our community is just by starring the GitHub repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "[Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "## Join our Slack!\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at http://slack.openmined.org\n",
    "\n",
    "## Join a Code Project!\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
    "\n",
    "[PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "[Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "## Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
