{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and model specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (1, 1)\n",
    "data = th.zeros(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5318]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Model Owner\n",
    "# Support fetch plan + AST tensor\n",
    "class Net(sy.Plan):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__(id=\"fc3\")\n",
    "        self.fc1 = nn.Linear(1,1)\n",
    "        self.add_to_state([\"fc1\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "plan = Net()\n",
    "    \n",
    "plan.build(data)\n",
    "print(plan(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "def restart_kernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "    \n",
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n",
      "WARNING: Grid nodes publish datasets online and are for EXPERIMENTAL use only.Deploy nodes at your own risk. Do not use OpenGrid with any data/models you wish to keep private.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Net Net id:fc3 owner:me built>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.fix_prec().share(bob, charlie, crypto_provider=dan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'success': True, 'message': 'Model saved with id: fc3'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice.serve_encrypted_model(plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True, 'models': ['fc3']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = alice.download_model(\"fc3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sh = data.fix_prec().share(bob, charlie, crypto_provider=dan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5310]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_copy(x_sh).get().float_prec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this should be done internally\n",
    "new_state_ids = []\n",
    "for state_id in fetched_plan.state_ids:\n",
    "    a_sh = me._objects[state_id].fix_prec().share(bob, charlie, crypto_provider=dan).get()\n",
    "    # TODO: this should be stored automatically\n",
    "    me._objects[a_sh.id] = a_sh\n",
    "    new_state_ids.append(a_sh.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89202407203, 56780661394, 54079972075, 63518858733, 6715421912, 68929474864]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_plan.state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_plan.replace_ids(fetched_plan.state_ids, new_state_ids)\n",
    "fetched_plan.state_ids = new_state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1420]])\n",
      "CPU times: user 15.4 s, sys: 5.39 s, total: 20.8 s\n",
      "Wall time: 18.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n",
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(fetched_plan(x_ptr).get().float_prec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net2\n"
     ]
    }
   ],
   "source": [
    "# Support fetching a plan\n",
    "plan_func = False\n",
    "\n",
    "if plan_func:\n",
    "    @sy.func2plan(args_shape=[(1,)], state={\"bias\": th.tensor([3.0])})\n",
    "    def plan_mult_3(x, state):\n",
    "        bias = state.read(\"bias\")\n",
    "        x = x * bias\n",
    "        return x\n",
    "else:\n",
    "    class Net(sy.Plan):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__(id=\"net2\")\n",
    "            self.fc1 = nn.Linear(1, 1)\n",
    "            self.add_to_state([\"fc1\"])\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.fc1(x)\n",
    "    \n",
    "    plan_mult_3 = Net()\n",
    "    plan_mult_3.build(th.tensor(1))\n",
    "\n",
    "sent_plan = plan_mult_3.send(alice)\n",
    "print(sent_plan.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "def restart_kernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "    \n",
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch as th\n",
    "import syft as sy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import grid as gr\n",
    "\n",
    "# Hook\n",
    "hook = sy.TorchHook(th)\n",
    "me = hook.local_worker\n",
    "me.is_client_worker = False\n",
    "    \n",
    "# Connect to nodes\n",
    "alice = gr.WebsocketGridClient(hook, \"http://localhost:3001\", id=\"Alice\")\n",
    "alice.connect()\n",
    "bob = gr.WebsocketGridClient(hook, \"http://localhost:3000\", id=\"Bob\")\n",
    "charlie = gr.WebsocketGridClient(hook, \"http://localhost:3002\", id=\"James\")\n",
    "dan = gr.WebsocketGridClient(hook, \"http://localhost:3003\", id=\"Dan\")\n",
    "bob.connect()\n",
    "charlie.connect()\n",
    "dan.connect()\n",
    "\n",
    "gr.connect_all_nodes([bob, alice, charlie, dan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch plan\n",
    "fetched_plan = alice.fetch_plan(\"net2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this should be done internally\n",
    "new_state_ids = []\n",
    "for state_id in fetched_plan.state_ids:\n",
    "    # TODO: we should not have direct access to the weights\n",
    "    a_sh = me._objects[state_id].get()\n",
    "    # TODO: this should be stored automatically\n",
    "    me._objects[a_sh.id] = a_sh\n",
    "    new_state_ids.append(a_sh.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_plan.replace_ids(fetched_plan.state_ids, new_state_ids)\n",
    "fetched_plan.state_ids = new_state_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2805], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = th.tensor([1.])\n",
    "print(fetched_plan(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
