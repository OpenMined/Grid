{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Introducing the Grid Network\n",
    "\n",
    "\n",
    "In the previous tutorials we explicitly connected to the workers in order to interact with them, this can be useful for use cases where we want to have control over where the data is stored (which node?) and who performs each role on the application.\n",
    "\n",
    "Another possible way to see Grid is that workers that are connected consist of a Grid Network.\n",
    "\n",
    "\n",
    "## What is the Grid Network?\n",
    "\n",
    "<p align=\"center\">\n",
    "<img height=\"600px\" width=\"600px\" src=\"https://github.com/OpenMined/rfcs/blob/master/20190821-grid-platform/DHT-grid.png?raw=true\">\n",
    "</p>\n",
    "\n",
    "\n",
    "This network can be seen by a user as a single interface: the Grid Gateway. The Gateway works like a special DNS component but it will route nodes by queries instead of domain names.\n",
    "\n",
    "It is important to emphasize: the Grid Gateway will not be able to perform any computation process on the nodes. It can not concentrate or centralize any data or model. It works as a brigde between a user that is outside of the grid network to get data / models that live inside the network.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img height=\"600px\" width=\"600px\" src=\"https://github.com/OpenMined/rfcs/blob/master/20190821-grid-platform/partially_grid.png?raw=true\">\n",
    "</p>\n",
    "\n",
    "With this fully distributed and descentralized architecure we can provide fault tolerance in a very transparent way.\n",
    "\n",
    "\n",
    "## Using the Grid Network\n",
    "\n",
    "\n",
    "In this notebook we'll use a grid network to host a toy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import grid as gr\n",
    "import syft as sy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the Grid Network\n",
    "\n",
    "We don't need to connect to each worker explictly we just connect to a gateway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout the example folders to learn how to setup a GridNetwork on Heroku!\n",
    "grid_network = gr.GridNetwork(\"http://opengridgateway.herokuapp.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "class Net(sy.Plan):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = th.nn.Linear(2, 1)\n",
    "        self.fc2 = th.nn.Linear(1, 1)\n",
    "        self.state += [\"fc1\", \"fc2\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model.build(th.tensor([1.0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_network.serve_model(model, model_id=\"toy_model\",allow_remote_inference=True, allow_download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7818])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_network.run_remote_inference(model_id=\"toy_model\", data=th.tensor([1.0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model was hosted at:  hospitalnode\n",
      "Grid Address:  http://hospitalnode.herokuapp.com/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n"
     ]
    }
   ],
   "source": [
    "worker = grid_network.query_model(model_id=\"toy_model\")\n",
    "\n",
    "print(\"This model was hosted at: \", worker.id)\n",
    "print(\"Grid Address: \", worker.uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7817554473876953]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:engineio.client:WebSocket connection was closed, aborting\n"
     ]
    }
   ],
   "source": [
    "worker.run_remote_inference(model_id=\"toy_model\", data=th.tensor([1.0, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disconnect from the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_network.disconnect_nodes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
