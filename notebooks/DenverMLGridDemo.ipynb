{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed model training with `torch.autograd` on OpenGrid\n",
    "\n",
    "**@jvmancuso** (or @jason on the OpenMined Slack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mUPDATE: \u001b[0mConnecting to IPFS... this can take a few seconds...\n",
      "\n",
      "\u001b[32mSUCCESS: \u001b[0mConnected!!! - My ID: client:Qma5efEQtBUxDonmSDajv9dZ52axH9MNULKTgVpXWK8Ak2\n",
      "all parts .... ['', 'Users', 'atrask', '.openmined']\n",
      "full path /\n",
      "full path /Users/\n",
      "full path /Users/atrask/\n",
      "full path /Users/atrask/.openmined/\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mQuerying known workers...\n",
      "\tWORKER: /p2p-circuit/ipfs/QmQabt3SWuDvjse9z7GAcH2BGQv4wH8bumkd4x5oXN2obX...\u001b[31mFAIL!!!\u001b[0m\n",
      "\tWORKER: /p2p-circuit/ipfs/QmXkWUybbTnfvFH8SUcrug6RGTLYTB23gSockKLxueR1vQ...\u001b[31mFAIL!!!\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mSearching for IPFS nodes - 1 found overall - 0 are OpenMined workers........          "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4d90f373d613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# instantiate client!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/grid-0.1.0-py3.6.egg/grid/clients/torch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, min_om_nodes, known_workers, include_github_known_workers, verbose)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mknown_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknown_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0minclude_github_known_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_github_known_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hook_service'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHookService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/grid-0.1.0-py3.6.egg/grid/clients/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, min_om_nodes, known_workers, include_github_known_workers, include_self_discovery, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;34m'listen_for_openmined_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListenForOpenMinedNodesService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_om_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 include_github_known_workers)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/grid-0.1.0-py3.6.egg/grid/services/listen_for_openmined_nodes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, worker, min_om_nodes, known_workers, include_github_known_workers)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mmin_om_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_om_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mknown_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknown_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             include_github_known_workers=include_github_known_workers)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload_github_known_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/grid-0.1.0-py3.6.egg/grid/services/listen_for_openmined_nodes.py\u001b[0m in \u001b[0;36mlisten_for_openmined_nodes\u001b[0;34m(self, min_om_nodes, known_workers, include_github_known_workers)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mnum_nodes_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mnum_nodes_om\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_openmined_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch # do not run this line after instantiating TorchClient\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from grid.clients.torch import TorchClient\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# instantiate client!\n",
    "client = TorchClient(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to find out who's connected to OpenGrid.  We'll then choose who we want to demo with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m ANCHOR - 1 - NAME:jm_anchor  Ping:0.09sec  CPUs:1  CPU Load:18.2  Disk-util:49.2%  RAM-util:36.7%  GPUs:[]\u001b[0m\n",
      "COMPUTE - 2 - NAME:jason@manc.us  Ping:0.05sec  CPUs:8  CPU Load:0.0  Disk-util:31.7%  RAM-util:27.9%  GPUs:[]\n"
     ]
    }
   ],
   "source": [
    "client.print_network_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['compute:QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4']\n"
     ]
    }
   ],
   "source": [
    "compute_nodes = [x for x in client if re.match('compute:', x)]\n",
    "assert len(compute_nodes) > 0\n",
    "\n",
    "print(compute_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compute_nodes = compute_nodes[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compute:QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop = compute_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now do remote Tensor ops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1\n",
       " 4  4\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,1],[2,2]])\n",
    "x.send_(laptop)\n",
    "y = x * x\n",
    "y.get_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beyond Tensors\n",
    "\n",
    "Tensor computation is sufficient for training most gradient-based models, but it's not convenient for doing so when backpropagation is involved.  To solve this, we'll want to use automatic differentiation using the Variable class from `torch.autograd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check out some new Grid-specific attributes that are useful to know about.  We'll do so with Variables this time, since we want to use autograd, but all the usual Tensor types have these attributes as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "======\n",
      "Grid-specific attributes\n",
      "======\n",
      "owners: ['client:QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4']\n",
      "id: 4082226712\n",
      "is_pointer: False\n"
     ]
    }
   ],
   "source": [
    "# Note: Variable is now a purely internal class in PyTorch v0.4.0,\n",
    "#       but OpenGrid currently depends on v0.3.1.\n",
    "#       We'll be updating just as soon as we can!\n",
    "\n",
    "x = Variable(torch.FloatTensor([[1,1],[2,2]]), requires_grad=True)\n",
    "y = Variable(torch.FloatTensor([[1,1],[2,2]]), requires_grad=True)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print('======\\nGrid-specific attributes\\n======')\n",
    "print('owners: {}'.format(x.owners))\n",
    "print('id: {}'.format(x.id))\n",
    "print('is_pointer: {}'.format(x.is_pointer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenGrid attributes:\n",
    "- The `owners` attribute tells us where the tensor's data lives.\n",
    "- The `id` attribute is a way for each machine's instance of OpenGrid to track which Torch objects they're holding locally, allowing different machines to request access to different objects.  This also allows each worker to know which tensors they need to perform computations on.\n",
    "- The `is_pointer` attribute tells us whether or not the object we're referring to is local or remote.  If it's local (is_pointer is False), we'll execute normal PyTorch code on it.  Otherwise, we'll send our command to the owner machine and have it perform the computation we want over there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll send our Variables like we did the tensor in our first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:[torch.FloatTensor - Locations:['compute:QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4']]\n",
      "======\n",
      "Grid-specific attributes\n",
      "======\n",
      "owners: ['compute:QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4']\n",
      "id: 4082226712\n",
      "is_pointer: True\n"
     ]
    }
   ],
   "source": [
    "x.send_(laptop)\n",
    "y.send_(laptop)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print('======\\nGrid-specific attributes\\n======')\n",
    "print('owners: {}'.format(x.owners))\n",
    "print('id: {}'.format(x.id))\n",
    "print('is_pointer: {}'.format(x.is_pointer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the change?  The location is different (we're now using a compute node with a different worker ID), and the `is_pointer` attribute changed to True.  The data is no longer on this machine; it's now on the worker's machine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to do some remote computation now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.matmul(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the result's attributes like we did for `x` and `y` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:[torch.FloatTensor - Locations:['compute:QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4']]\n",
      "======\n",
      "Grid-specific attributes\n",
      "======\n",
      "owners: ['compute:QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4']\n",
      "id: 2131795\n",
      "is_pointer: True\n"
     ]
    }
   ],
   "source": [
    "print(z)\n",
    "\n",
    "print('======\\nGrid-specific attributes\\n======')\n",
    "print('owners: {}'.format(z.owners))\n",
    "print('id: {}'.format(z.id))\n",
    "print('is_pointer: {}'.format(z.is_pointer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is this cool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't have to change anything in our Torch code!  The command we used (`matmul`) is identical to the normal PyTorch command, but the computation is being performed elsewhere.\n",
    "\n",
    "I also didn't cherry-pick this example; any method or function that inputs and outputs Tensor/Variable objects can be used in this exact same way, as long as those objects are stored somewhere on OpenGrid and we have a local pointer to those objects.\n",
    "\n",
    "Another cool thing is that although the computation result is on the other machine, we still have access to a local pointer for the Variable.  We can use that pointer in future computations, chaining together commands for remote machines without having to retrieve and send the underlying data between each command. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sum = z.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used Variables so that we can take advantage of autograd.  Let's make sure that works, by taking the derivative of `z_sum` with respect to `x` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sum.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivatives with respect to `x` and `y` are now stored in `x.grad` and `y.grad`, but we'll need to retrieve `x` and `y` to access those.  That's okay for this use case, since we're not concerned about data privacy right now.  Figuring out how to call `get_` on the grad itself would be another useful contribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2  4\n",
      " 2  4\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n",
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.get_()\n",
    "y.get_()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now computed derivatives on a remote machine, and we did so interactively with a dynamic computation graph over a peer-to-peer network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Training a model with distributed gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, IPFS has some limitations around how much data can be transferred in one block.  They've introduced a sharding mechanism to get around this ([see here](https://github.com/ipfs/go-ipfs/pull/3042)), but it's not currently being used in OpenGrid.  This could be a cool first contribution to the project! See [this issue](https://github.com/OpenMined/Grid/issues/181) for more info.\n",
    "\n",
    "Thus, we'll use a dataset with relatively low dimensionality for now -- the Boston housing prices dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y).type(torch.FloatTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "mean = X.mean(0, keepdim=True)\n",
    "dev = X.std(0, keepdim=True)\n",
    "mean[:, 3] = 0. # the feature at column 3 is binary,\n",
    "dev[:, 3] = 1.  # so I'd rather not standardize it\n",
    "X = (X - mean) / dev\n",
    "X_test = (X_test - mean) / dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "batch_size = 8\n",
    "learning_rate = .01\n",
    "epochs = 5\n",
    "update_master_every = 3\n",
    "\n",
    "# architecture\n",
    "input_shape = X.shape[1]\n",
    "first_neurons = 64\n",
    "second_neurons = 32\n",
    "try: # will work for multivariate regression tasks too\n",
    "    dep_vars = y.size(1)\n",
    "except RuntimeError:\n",
    "    dep_vars = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch utilities for supplying data to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(X, y)\n",
    "test = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_load = DataLoader(train, batch_size = 8, drop_last=True)\n",
    "ts_load = DataLoader(test, batch_size = 8, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocating training batches to each worker\n",
    "\n",
    "Once we send batches out to participating workers, they won't need to move around for the rest of training -- they'll only be sharing the model.  Our client machine will play the role of Parameter Server.  This is known as \"data parallelism\" (as opposed to \"model parallelism\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 15.8 ms, total: 240 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "allocated = []\n",
    "\n",
    "for (ix, (x_i, y_i)) in enumerate(tr_load):\n",
    "    x_i = Variable(x_i, requires_grad = True)\n",
    "    y_i = Variable(y_i, requires_grad = True)\n",
    "    x_i.send_(compute_nodes[ix % len(compute_nodes)])\n",
    "    y_i.send_(compute_nodes[ix % len(compute_nodes)])\n",
    "    allocated.append((x_i, y_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allocated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network parameters initialized.\n"
     ]
    }
   ],
   "source": [
    "W_0 = nn.Parameter(torch.FloatTensor(input_shape, first_neurons))\n",
    "W_1 = nn.Parameter(torch.FloatTensor(first_neurons, second_neurons))\n",
    "W_2 = nn.Parameter(torch.FloatTensor(second_neurons, dep_vars))\n",
    "\n",
    "# initialize properly\n",
    "relu_gain = nn.init.calculate_gain('relu')\n",
    "lin_gain = nn.init.calculate_gain('linear')\n",
    "\n",
    "nn.init.xavier_normal(W_0, gain=relu_gain)\n",
    "nn.init.xavier_normal(W_1, gain=relu_gain)\n",
    "nn.init.xavier_normal(W_2, gain=lin_gain)\n",
    "\n",
    "print('Network parameters initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    \"\"\"Rectified linear activation\"\"\"\n",
    "    return torch.clamp(x, min=0.)\n",
    "\n",
    "def linear(x, w):\n",
    "    \"\"\"Linear transformation of x by w\"\"\"\n",
    "    return torch.matmul(x,w)\n",
    "\n",
    "def mse(y_hat, y_true):\n",
    "    \"\"\"Mean-squared error\"\"\"\n",
    "    return torch.mean(torch.pow(y_hat - y_true, 2), dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient update helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_grads(grads):\n",
    "    \"\"\"Average a sequence of gradients\"\"\"\n",
    "    return torch.mean(torch.cat(grads))\n",
    "\n",
    "def update_params(param, grad, alpha):\n",
    "    \"\"\"Update parameter tensor with standard mini-batch gradient descent\"\"\"\n",
    "    return param - alpha * grad\n",
    "\n",
    "def reset_flags(param):\n",
    "    \"\"\"Resets flags for a Parameter that's experienced an in-place operation\"\"\"\n",
    "    param.requires_grad = True\n",
    "    param.volatile = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done!\n",
      "Epoch 2 done!\n",
      "Epoch 3 done!\n",
      "Epoch 4 done!\n",
      "Epoch 5 done!\n"
     ]
    }
   ],
   "source": [
    "# Initialize gradient buffers\n",
    "W_0_grads = []\n",
    "W_1_grads = []\n",
    "W_2_grads = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Loop over distributed batches\n",
    "    for ix, (x_i, y_i) in enumerate(allocated):\n",
    "        # Broadcast current weights to workers\n",
    "        W_0_clones = [W_0.clone().send_(node) for node in compute_nodes]\n",
    "        W_1_clones = [W_1.clone().send_(node) for node in compute_nodes]\n",
    "        W_2_clones = [W_2.clone().send_(node) for node in compute_nodes]\n",
    "\n",
    "        # Pull pointers from clone list\n",
    "        W_0_tmp = W_0_clones[ix % len(compute_nodes)]\n",
    "        W_1_tmp = W_1_clones[ix % len(compute_nodes)]\n",
    "        W_2_tmp = W_2_clones[ix % len(compute_nodes)]\n",
    "\n",
    "        # Forward pass\n",
    "        act_0 = relu(linear(x_i, W_0_tmp))\n",
    "        act_1 = relu(linear(act_0, W_1_tmp))\n",
    "        y_hat = linear(act_1, W_2_tmp).view(-1)\n",
    "\n",
    "        # Calculate MSE loss and perform backprop\n",
    "        y_i = y_i.type_as(y_hat) # type-safety\n",
    "        loss = mse(y_hat, y_i)\n",
    "        loss.backward()\n",
    "\n",
    "        # Recall parameters\n",
    "        W_0_tmp.get_()\n",
    "        W_1_tmp.get_()\n",
    "        W_2_tmp.get_()\n",
    "\n",
    "        # Store parameter grads\n",
    "        W_0_grads.append(W_0_tmp.grad)\n",
    "        W_1_grads.append(W_1_tmp.grad)\n",
    "        W_2_grads.append(W_2_tmp.grad)\n",
    "\n",
    "        # Update master parameters\n",
    "        if ix % update_master_every == 0:\n",
    "            W_0_grad = average_grads(W_0_grads)\n",
    "            W_1_grad = average_grads(W_1_grads)\n",
    "            W_2_grad = average_grads(W_2_grads)\n",
    "\n",
    "            W_0 = update_params(W_0, W_0_grad, alpha=learning_rate)\n",
    "            W_1 = update_params(W_1, W_1_grad, alpha=learning_rate)\n",
    "            W_2 = update_params(W_2, W_2_grad, alpha=learning_rate)\n",
    "\n",
    "            # We've overridden Variables in-place, which breaks the computation graph internally\n",
    "            # That's what we wanted to do, but we'll need to clean up a bit to be able to keep going\n",
    "            reset_flags(W_0)\n",
    "            reset_flags(W_1)\n",
    "            reset_flags(W_2)\n",
    "            \n",
    "            # Clean out parameter server grad buffers\n",
    "            W_0_grads = []\n",
    "            W_1_grads = []\n",
    "            W_2_grads = []\n",
    "            \n",
    "\n",
    "    print(\"Epoch {} done!\".format(epoch + 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
