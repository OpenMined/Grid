{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, this requires using PyTorch v0.3.1.  Somewhere between 0.3.1 and 0.4.0 parts of the backend were significantly rewritten, preventing us from performing the following hacks. (Likely has to do with them fusing Variable and Tensor).  That may change once their new API stabilizes.\n",
    "\n",
    "The nice thing about how this is working is that it should be general enough to work for compute, tree, and federated modes of Grid, depending on how the `receive` function works under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonmancuso/anaconda/envs/openmined/lib/python3.6/site-packages/h5py-2.7.1-py3.6-macosx-10.7-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from grid.clients.torch import TorchClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34mUPDATE: \u001b[0mConnecting to IPFS... this can take a few seconds...\n",
      "\n",
      "\u001b[32mSUCCESS: \u001b[0mConnected!!! - My ID: QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mQuerying known workers...\n",
      "\tWORKER: /p2p-circuit/ipfs/Qmaosc64H6Y29VFCFYJzJXCX9AuRp7RCsekLmajHNVEARD...\u001b[32mSUCCESS!!!\u001b[0m\n",
      "\tWORKER: /p2p-circuit/ipfs/QmQabt3SWuDvjse9z7GAcH2BGQv4wH8bumkd4x5oXN2obX...\u001b[31mFAIL!!!\u001b[0m\n",
      "\n",
      "\u001b[34mUPDATE: \u001b[0mSearching for IPFS nodes - 27 found overall - 5 are OpenMined workers          \n",
      "\n",
      "\u001b[32mSUCCESS: \u001b[0mFound 5 OpenMined nodes!!!\n",
      "\n",
      "\u001b[90m ANCHOR - 0 - ID:VEARD  Ping:0.05sec  CPUs:1  CPU Load:4.2  Disk-util:97.7%  RAM-util:2.0%  GPUs:[]\u001b[0m\n",
      "COMPUTE - 1 - ID:LJqCp  Ping:0.40sec  CPUs:2  CPU Load:1.5  Disk-util:2.1%  RAM-util:86.4%  GPUs:[0 : Tesla K80 : 2/11439]\n",
      "COMPUTE - 2 - ID:JGr7h  Ping:0.42sec  CPUs:2  CPU Load:1.5  Disk-util:2.1%  RAM-util:86.5%  GPUs:[0 : Tesla K80 : 2/11439]\n",
      "COMPUTE - 3 - ID:K4Gbz  Ping:0.38sec  CPUs:2  CPU Load:2.9  Disk-util:2.1%  RAM-util:80.3%  GPUs:[0 : Tesla K80 : 10891/11439]\n",
      "NODE    -   - - timeout - -\n"
     ]
    }
   ],
   "source": [
    "client = TorchClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service_self = client.services['torch_service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# service_self = client.services['torch_service']\n",
    "# def hook_float_tensor___init__(service_self):\n",
    "#     torch.FloatTensor.old___init__ = torch.FloatTensor.__init__\n",
    "#     def new___init__(self, *args, **kwargs):\n",
    "#         self.old___init__(*args, **kwargs)\n",
    "#         self = service_self.register_object(self,False)\n",
    "\n",
    "#     torch.FloatTensor.__init__ = new___init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import inspect\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from functools import wraps, partial, partialmethod\n",
    "from types import *\n",
    "import imp\n",
    "# from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_workers_function(worker_ids):\n",
    "    def decorate(func):\n",
    "        @wraps(func)\n",
    "        def send_to_workers(*args, **kwargs):\n",
    "            part = func(*args, **kwargs)\n",
    "            command = compile_command(part)\n",
    "            for worker in worker_ids:\n",
    "                print(\"Placeholder print for sending command to worker {}\".format(worker))\n",
    "                args, kwargs = send_command(command)\n",
    "            receive_commands(worker_ids)  ## Probably needs to happen async\n",
    "            return args, kwargs\n",
    "        return send_to_workers\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_workers_method(worker_ids):\n",
    "    def decorate(method):\n",
    "        @wraps(method)\n",
    "        def send_to_workers(self, *args, **kwargs):\n",
    "            part = method(self, *args, **kwargs)\n",
    "            if self.is_pointer_to_remote:\n",
    "                command = compile_command(part)\n",
    "                for worker in worker_ids:\n",
    "                    print(\"Placeholder print for sending command to worker {}\".format(worker))\n",
    "                    args, kwargs = send_command(command)\n",
    "                receive_commands(worker_ids)  ## Probably needs to happen async\n",
    "                return args, kwargs\n",
    "            else:\n",
    "                print('in there')\n",
    "                print(service_self)\n",
    "                result = part.func(*args, **kwargs)\n",
    "                try:\n",
    "                    getattr(result, 'id')\n",
    "                    return result\n",
    "                except:\n",
    "                    return service_self.register_object(result, self.is_pointer_to_remote)\n",
    "        return send_to_workers\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Slightly modified to remove parent class dependency\n",
    "# torch.FloatTensor.old___init__ = torch.FloatTensor.__init__\n",
    "# def hook_float_tensor___init__():\n",
    "#     def new___init__(self, tensor, owner=client.services['torch_service'], *args, **kwargs):\n",
    "#         super(torch.FloatTensor, self).__init__(*args, **kwargs)\n",
    "#         self = owner.register_object(self, False)\n",
    "\n",
    "#     torch.FloatTensor.__init__ = new___init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# service_self = client.services['torch_service']\n",
    "# def hook_float_tensor___init__(service_self):\n",
    "#     def new___init__(self, *args, **kwargs):\n",
    "#         super(torch.FloatTensor, self).__init__(*args, **kwargs)\n",
    "#         self = service_self.register_object(self,False)\n",
    "\n",
    "#     torch.FloatTensor.__init__ = new___init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def assign_workers_factory(worker_ids):\n",
    "#     def decorate(method):\n",
    "#         @wraps(method)\n",
    "#         def send_to_workers(self, *args, **kwargs):\n",
    "#             part = method(self, *args, **kwargs)\n",
    "#             command = compile_command(part)\n",
    "#             for worker in worker_ids:\n",
    "#                 print(\"Placeholder print for sending command to worker {}\".format(worker))\n",
    "#                 args, kwargs = send_command(command)\n",
    "#             receive_commands(worker_ids)  ## Probably needs to happen async\n",
    "#             return old_init(*args, **kwargs)\n",
    "#         return send_to_workers\n",
    "#     return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pass_func_args(func):\n",
    "    @wraps(func)\n",
    "    def pass_args(*args, **kwargs):\n",
    "        return partial(func, *args, **kwargs)\n",
    "    return pass_args\n",
    "\n",
    "def pass_method_args(method):\n",
    "    @wraps(method)\n",
    "    def pass_args(*args, **kwargs):\n",
    "        return partialmethod(method, *args, **kwargs)\n",
    "    return pass_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def send_command(command):\n",
    "    print(command)\n",
    "    print('===========')\n",
    "    print()\n",
    "    return command['args'], command['kwargs']\n",
    "\n",
    "def receive_commands(worker_ids):\n",
    "    print('Placeholder print for receiving commands from workers in the following list')\n",
    "    print(worker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_command(partial_func):\n",
    "    func = partial_func.func\n",
    "    args = partial_func.args\n",
    "    kwargs = partial_func.keywords\n",
    "    command = {}\n",
    "    command['command'] = func.__name__\n",
    "    command['command_type'] = type(func)\n",
    "    command['args'] = args\n",
    "    command['kwargs'] = kwargs\n",
    "    command['arg_types'] = [type(x) for x in args]\n",
    "    command['kwarg_types'] = [type(kwargs[x]) for x in kwargs]\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.FloatTensor.__delattr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for attr in dir(torch):\n",
    "    if attr == 'typename':\n",
    "        continue\n",
    "    if type(torch.__getattribute__(attr)) in [FunctionType, BuiltinFunctionType]:\n",
    "        torch.__setattr__(attr, assign_workers_function(['A1','B1', 'B2'])(pass_func_args(torch.__getattribute__(attr))))\n",
    "        \n",
    "for attr in dir(torch.FloatTensor):\n",
    "    lit = getattr(torch.FloatTensor, attr)\n",
    "    is_desc = inspect.ismethoddescriptor(lit)\n",
    "    is_func = type(lit)==FunctionType\n",
    "    is_mappingproxy = attr == '__dict__'\n",
    "    try:\n",
    "        is_service_func = 'TorchService' in lit.__qualname__\n",
    "    except:\n",
    "        is_service_func = False\n",
    "    is_base = attr in dir(object)\n",
    "    is_none = lit is None\n",
    "    if is_desc or (is_func and not is_service_func) and not is_base:\n",
    "        print(attr)\n",
    "        setattr(torch.FloatTensor, 'old_{}'.format(attr), lit)\n",
    "        setattr(torch.FloatTensor, attr, assign_workers_method(['A1','B1', 'B2'])(pass_method_args(lit)))\n",
    "    else:\n",
    "        print(attr, ' skipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/Users/jasonmancuso/anaconda/envs/openmined/lib/python3.6/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__add__  set\n",
      "__and__  set\n",
      "__array__  set\n",
      "__array_wrap__  set\n",
      "__bool__  set\n",
      "__class__  skipped\n",
      "__deepcopy__  set\n",
      "__delattr__  set\n",
      "__delitem__  set\n",
      "__dict__  skipped\n",
      "__dir__  set\n",
      "__div__  set\n",
      "__doc__  skipped\n",
      "__eq__  set\n",
      "__float__  set\n",
      "__format__  set\n",
      "__ge__  set\n",
      "__getattribute__  set\n",
      "__getitem__  set\n",
      "__getstate__  set\n",
      "__gt__  set\n",
      "__hash__  set\n",
      "__iadd__  set\n",
      "__iand__  set\n",
      "__idiv__  set\n",
      "__ilshift__  set\n",
      "__imul__  set\n",
      "__init__  skipped\n",
      "__init_subclass__  skipped\n",
      "__int__  set\n",
      "__invert__  set\n",
      "__ior__  set\n",
      "__ipow__  set\n",
      "__irshift__  set\n",
      "__isub__  set\n",
      "__iter__  set\n",
      "__itruediv__  set\n",
      "__ixor__  set\n",
      "__le__  set\n",
      "__len__  set\n",
      "__long__  set\n",
      "__lshift__  set\n",
      "__lt__  set\n",
      "__matmul__  set\n",
      "__mod__  set\n",
      "__module__  skipped\n",
      "__mul__  set\n",
      "__ne__  set\n",
      "__neg__  set\n",
      "__new__  skipped\n",
      "__nonzero__  set\n",
      "__or__  set\n",
      "__pow__  set\n",
      "__radd__  set\n",
      "__rdiv__  set\n",
      "__reduce__  set\n",
      "__reduce_ex__  set\n",
      "__repr__  skipped\n",
      "__rmul__  set\n",
      "__rpow__  set\n",
      "__rshift__  set\n",
      "__rsub__  set\n",
      "__rtruediv__  set\n",
      "__setattr__  set\n",
      "__setitem__  set\n",
      "__setstate__  set\n",
      "__sizeof__  set\n",
      "__str__  set\n",
      "__sub__  set\n",
      "__subclasshook__  skipped\n",
      "__truediv__  set\n",
      "__weakref__  skipped\n",
      "__xor__  set\n",
      "_advanced_index_add  set\n",
      "_advanced_index_select  set\n",
      "_cdata  skipped\n",
      "_check_advanced_indexing  set\n",
      "_new_with_metadata_file  skipped\n",
      "_set_index  set\n",
      "_sparse_mask  set\n",
      "_torch  skipped\n",
      "_write_metadata  set\n",
      "abs  set\n",
      "abs_  set\n",
      "acos  set\n",
      "acos_  set\n",
      "add  set\n",
      "add_  set\n",
      "addbmm  set\n",
      "addbmm_  set\n",
      "addcdiv  set\n",
      "addcdiv_  set\n",
      "addcmul  set\n",
      "addcmul_  set\n",
      "addmm  set\n",
      "addmm_  set\n",
      "addmv  set\n",
      "addmv_  set\n",
      "addr  set\n",
      "addr_  set\n",
      "apply_  set\n",
      "asin  set\n",
      "asin_  set\n",
      "atan  set\n",
      "atan2  set\n",
      "atan2_  set\n",
      "atan_  set\n",
      "baddbmm  set\n",
      "baddbmm_  set\n",
      "bernoulli  set\n",
      "bernoulli_  set\n",
      "bmm  set\n",
      "btrifact  set\n",
      "btrisolve  set\n",
      "byte  set\n",
      "cauchy_  set\n",
      "ceil  set\n",
      "ceil_  set\n",
      "char  set\n",
      "chunk  set\n",
      "clamp  set\n",
      "clamp_  set\n",
      "clone  set\n",
      "contiguous  set\n",
      "copy_  set\n",
      "cos  set\n",
      "cos_  set\n",
      "cosh  set\n",
      "cosh_  set\n",
      "cpu  set\n",
      "cross  set\n",
      "cuda  set\n",
      "cumprod  set\n",
      "cumsum  set\n",
      "data  skipped\n",
      "data_ptr  set\n",
      "de  skipped\n",
      "diag  set\n",
      "dim  set\n",
      "dist  set\n",
      "div  set\n",
      "div_  set\n",
      "dot  set\n",
      "double  set\n",
      "eig  set\n",
      "element_size  set\n",
      "eq  set\n",
      "eq_  set\n",
      "equal  set\n",
      "erf  set\n",
      "erf_  set\n",
      "erfinv  set\n",
      "erfinv_  set\n",
      "exp  set\n",
      "exp_  set\n",
      "expand  set\n",
      "expand_as  set\n",
      "exponential_  set\n",
      "fill_  set\n",
      "float  set\n",
      "floor  set\n",
      "floor_  set\n",
      "fmod  set\n",
      "fmod_  set\n",
      "frac  set\n",
      "frac_  set\n",
      "gather  set\n",
      "ge  set\n",
      "ge_  set\n",
      "gels  set\n",
      "geometric_  set\n",
      "geqrf  set\n",
      "ger  set\n",
      "gesv  set\n",
      "get  skipped\n",
      "gt  set\n",
      "gt_  set\n",
      "half  set\n",
      "histc  set\n",
      "index  set\n",
      "index_add_  set\n",
      "index_copy_  set\n",
      "index_fill_  set\n",
      "index_select  set\n",
      "int  set\n",
      "inverse  set\n",
      "is_contiguous  set\n",
      "is_cuda  skipped\n",
      "is_pinned  set\n",
      "is_same_size  set\n",
      "is_set_to  set\n",
      "is_shared  set\n",
      "is_signed  set\n",
      "is_sparse  skipped\n",
      "kthvalue  set\n",
      "le  set\n",
      "le_  set\n",
      "lerp  set\n",
      "lerp_  set\n",
      "lgamma  set\n",
      "lgamma_  set\n",
      "log  set\n",
      "log1p  set\n",
      "log1p_  set\n",
      "log_  set\n",
      "log_normal_  set\n",
      "long  set\n",
      "lt  set\n",
      "lt_  set\n",
      "map2_  set\n",
      "map_  set\n",
      "masked_copy_  set\n",
      "masked_fill_  set\n",
      "masked_scatter_  set\n",
      "masked_select  set\n",
      "matmul  set\n",
      "max  set\n",
      "mean  set\n",
      "median  set\n",
      "min  set\n",
      "mm  set\n",
      "mode  set\n",
      "mul  set\n",
      "mul_  set\n",
      "multinomial  set\n",
      "mv  set\n",
      "narrow  set\n",
      "ndimension  set\n",
      "ne  set\n",
      "ne_  set\n",
      "neg  set\n",
      "neg_  set\n",
      "nelement  set\n",
      "new  set\n",
      "nonzero  set\n",
      "norm  set\n",
      "normal_  set\n",
      "numel  set\n",
      "numpy  set\n",
      "old__repr__  set\n",
      "orgqr  set\n",
      "ormqr  set\n",
      "permute  set\n",
      "pin_memory  set\n",
      "potrf  set\n",
      "potri  set\n",
      "potrs  set\n",
      "pow  set\n",
      "pow_  set\n",
      "process_command  skipped\n",
      "prod  set\n",
      "pstrf  set\n",
      "put_  set\n",
      "qr  set\n",
      "random_  set\n",
      "reciprocal  set\n",
      "reciprocal_  set\n",
      "remainder  set\n",
      "remainder_  set\n",
      "renorm  set\n",
      "renorm_  set\n",
      "repeat  set\n",
      "resize_  set\n",
      "resize_as_  set\n",
      "round  set\n",
      "round_  set\n",
      "rsqrt  set\n",
      "rsqrt_  set\n",
      "scatter_  set\n",
      "scatter_add_  set\n",
      "select  set\n",
      "send  skipped\n",
      "ser  skipped\n",
      "set_  set\n",
      "shape  skipped\n",
      "share_memory_  set\n",
      "short  set\n",
      "sigmoid  set\n",
      "sigmoid_  set\n",
      "sign  set\n",
      "sign_  set\n",
      "sin  set\n",
      "sin_  set\n",
      "sinh  set\n",
      "sinh_  set\n",
      "size  set\n",
      "sort  set\n",
      "split  set\n",
      "sqrt  set\n",
      "sqrt_  set\n",
      "squeeze  set\n",
      "squeeze_  set\n",
      "std  set\n",
      "storage  set\n",
      "storage_offset  set\n",
      "storage_type  skipped\n",
      "stride  set\n",
      "sub  set\n",
      "sub_  set\n",
      "sum  set\n",
      "svd  set\n",
      "symeig  set\n",
      "t  set\n",
      "t_  set\n",
      "take  set\n",
      "tan  set\n",
      "tan_  set\n",
      "tanh  set\n",
      "tanh_  set\n",
      "tolist  set\n",
      "topk  set\n",
      "trace  set\n",
      "transpose  set\n",
      "transpose_  set\n",
      "tril  set\n",
      "tril_  set\n",
      "triu  set\n",
      "triu_  set\n",
      "trtrs  set\n",
      "trunc  set\n",
      "trunc_  set\n",
      "type  set\n",
      "type_as  set\n",
      "unfold  set\n",
      "uniform_  set\n",
      "unsqueeze  set\n",
      "unsqueeze_  set\n",
      "var  set\n",
      "view  set\n",
      "view_as  set\n",
      "zero_  set\n"
     ]
    }
   ],
   "source": [
    "for attr in dir(torch.FloatTensor):\n",
    "    lit = getattr(torch.FloatTensor, attr)\n",
    "    is_desc = inspect.ismethoddescriptor(lit)\n",
    "    is_func = type(lit)==FunctionType\n",
    "    is_mappingproxy = attr == '__dict__'\n",
    "    try:\n",
    "        is_service_func = 'TorchService' in lit.__qualname__ \n",
    "    except:\n",
    "        is_service_func = False\n",
    "    is_prop = isinstance(lit, property)\n",
    "    is_bool = isinstance(lit, bool)\n",
    "    is_base = lit in dir(object)\n",
    "    is_none = lit is None\n",
    "    if is_desc or (is_func and not is_service_func):\n",
    "        print(attr, ' set')\n",
    "    else:\n",
    "        print(attr, ' skipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp.reload(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor.is_sparse.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__bool__',\n",
       " '__ceil__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floor__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__le__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__trunc__',\n",
       " '__xor__',\n",
       " 'bit_length',\n",
       " 'conjugate',\n",
       " 'denominator',\n",
       " 'from_bytes',\n",
       " 'imag',\n",
       " 'numerator',\n",
       " 'real',\n",
       " 'to_bytes']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.FloatTensor.is_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2ab99bdcec83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/openmined/lib/python3.6/site-packages/grid-0.1.0-py3.6.egg/grid/services/torch/torch_service.py\u001b[0m in \u001b[0;36mnew___init__\u001b[0;34m(self, tensor, owner, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mnew___init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew___init__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/openmined/lib/python3.6/site-packages/grid-0.1.0-py3.6.egg/grid/services/torch/torch_service.py\u001b[0m in \u001b[0;36mregister_object\u001b[0;34m(self, obj, is_pointer_to_remote)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_pointer_to_remote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'owner registered'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fdc865f601e5>\u001b[0m in \u001b[0;36msend_to_workers\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msend_to_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pointer_to_remote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mworker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworker_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m<ipython-input-7-fdc865f601e5>\u001b[0m in \u001b[0;36msend_to_workers\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msend_to_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pointer_to_remote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mworker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworker_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "y = torch.FloatTensor([[2,2],[2,2]])\n",
    "z = torch.FloatTensor([[1,1],[1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.FloatTensor' object has no attribute 'old_add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3216867950b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.FloatTensor' object has no attribute 'old_add'"
     ]
    }
   ],
   "source": [
    "x = y.old_add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owner registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 3  3\n",
       " 3  3\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_self.register_object(x, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.is_pointer_to_remote = True\n",
    "z.is_pointer_to_remote = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = y.add(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owner registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 3  3\n",
       " 3  3\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_self.register_object(x, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3  3\n",
       " 3  3\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'QmeVrfEayAzvVM9Ujhyu4SjtQnNmQmmF7dvyRtMmzc9wh4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TorchClient' object has no attribute 'register_object'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-41dbe26c77f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TorchClient' object has no attribute 'register_object'"
     ]
    }
   ],
   "source": [
    "client.register_object(x, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fc4093f1e82f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "args, kwargs = torch.mm(y, mat2 = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "{'command': 'add', 'command_type': <class 'builtin_function_or_method'>, 'args': (\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ",), 'kwargs': {'other': \n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "}, 'arg_types': [<class 'torch.FloatTensor'>], 'kwarg_types': [<class 'torch.FloatTensor'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "{'command': 'add', 'command_type': <class 'builtin_function_or_method'>, 'args': (\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ",), 'kwargs': {'other': \n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "}, 'arg_types': [<class 'torch.FloatTensor'>], 'kwarg_types': [<class 'torch.FloatTensor'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B2\n",
      "{'command': 'add', 'command_type': <class 'builtin_function_or_method'>, 'args': (\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ",), 'kwargs': {'other': \n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "}, 'arg_types': [<class 'torch.FloatTensor'>], 'kwarg_types': [<class 'torch.FloatTensor'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'B1', 'B2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((\n",
       "   2  2\n",
       "   2  2\n",
       "  [torch.FloatTensor of size 2x2],), {'other': \n",
       "   1  1\n",
       "   1  1\n",
       "  [torch.FloatTensor of size 2x2]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(y, other = z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch._C.add'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add.__module__+'.'+torch.add.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.add.__name__ in dir(torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor.__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__objclass__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__text_signature__']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.FloatTensor.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hook_var():\n",
    "    def new___init__(self, *args, **kwargs):\n",
    "        super(Variable, self).__init__(*args, **kwargs)\n",
    "        self.id = random.randint(0, 1e10)\n",
    "    Variable.__init__ = new___init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hook_add(worker_ids):\n",
    "    @assign_workers(worker_ids)\n",
    "    def new_add(self, other):\n",
    "        frame = inspect.currentframe()\n",
    "        command = compile_command('add', frame, self.id)\n",
    "        return command\n",
    "    \n",
    "    @assign_workers(worker_ids)\n",
    "    def new___add__(self, other):\n",
    "        frame = inspect.currentframe()\n",
    "        command = compile_command('__add__', frame, self.id)\n",
    "        return command\n",
    "    \n",
    "    Variable.add = new_add\n",
    "    Variable.__add__ = new___add__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutogradClosureFactory False\n",
      "ByteStorage False\n",
      "ByteTensor False\n",
      "CharStorage False\n",
      "CharTensor False\n",
      "DoubleStorage False\n",
      "DoubleTensor False\n",
      "FatalError False\n",
      "FloatStorage False\n",
      "FloatTensor False\n",
      "Generator False\n",
      "Graph False\n",
      "HalfStorage False\n",
      "HalfStorageBase False\n",
      "HalfTensor False\n",
      "HalfTensorBase False\n",
      "IntStorage False\n",
      "IntTensor False\n",
      "LongStorage False\n",
      "LongTensor False\n",
      "Node False\n",
      "ShortStorage False\n",
      "ShortTensor False\n",
      "Size False\n",
      "Storage False\n",
      "Tensor False\n",
      "TracingState False\n",
      "Type False\n",
      "Use False\n",
      "_C False\n",
      "_StorageBase False\n",
      "_TensorBase False\n",
      "__all__ False\n",
      "__builtins__ False\n",
      "__cached__ False\n",
      "__doc__ True\n",
      "__file__ False\n",
      "__loader__ False\n",
      "__name__ False\n",
      "__package__ False\n",
      "__path__ False\n",
      "__spec__ False\n",
      "__version__ False\n",
      "_import_dotted_name False\n",
      "_six False\n",
      "_storage_classes False\n",
      "_tensor_classes False\n",
      "_tensor_str False\n",
      "_thnn False\n",
      "_utils False\n",
      "abs True\n",
      "acos True\n",
      "add True\n",
      "addbmm True\n",
      "addcdiv True\n",
      "addcmul True\n",
      "addmm True\n",
      "addmv True\n",
      "addr True\n",
      "arange False\n",
      "asin True\n",
      "atan True\n",
      "atan2 True\n",
      "autograd False\n",
      "backends False\n",
      "baddbmm True\n",
      "bernoulli True\n",
      "bmm True\n",
      "btrifact True\n",
      "btrisolve True\n",
      "btriunpack False\n",
      "cat False\n",
      "ceil True\n",
      "chunk True\n",
      "clamp True\n",
      "cos True\n",
      "cosh True\n",
      "cross True\n",
      "cuda True\n",
      "cumprod True\n",
      "cumsum True\n",
      "default_generator False\n",
      "diag True\n",
      "dist True\n",
      "distributed False\n",
      "distributions False\n",
      "div True\n",
      "dot True\n",
      "dsmm False\n",
      "eig True\n",
      "eq True\n",
      "equal True\n",
      "erf True\n",
      "erfinv True\n",
      "exp True\n",
      "eye False\n",
      "floor True\n",
      "fmod True\n",
      "frac True\n",
      "from_numpy False\n",
      "functional False\n",
      "gather True\n",
      "ge True\n",
      "gels True\n",
      "geqrf True\n",
      "ger True\n",
      "gesv True\n",
      "get_num_threads False\n",
      "get_rng_state False\n",
      "gt True\n",
      "has_cudnn False\n",
      "histc True\n",
      "hsmm False\n",
      "index_select True\n",
      "initial_seed False\n",
      "inverse True\n",
      "is_storage False\n",
      "is_tensor False\n",
      "jit False\n",
      "kthvalue True\n",
      "le True\n",
      "lerp True\n",
      "lgamma True\n",
      "linspace False\n",
      "load False\n",
      "log True\n",
      "log1p True\n",
      "logspace False\n",
      "lt True\n",
      "manual_seed False\n",
      "masked_select True\n",
      "matmul True\n",
      "max True\n",
      "mean True\n",
      "median True\n",
      "min True\n",
      "mm True\n",
      "mode True\n",
      "mul True\n",
      "multinomial True\n",
      "multiprocessing False\n",
      "mv True\n",
      "ne True\n",
      "neg True\n",
      "nn False\n",
      "nonzero True\n",
      "norm True\n",
      "normal False\n",
      "np False\n",
      "numel True\n",
      "ones False\n",
      "ones_like False\n",
      "onnx False\n",
      "optim False\n",
      "orgqr True\n",
      "ormqr True\n",
      "potrf True\n",
      "potri True\n",
      "potrs True\n",
      "pow True\n",
      "prod True\n",
      "pstrf True\n",
      "qr True\n",
      "rand False\n",
      "randn False\n",
      "random False\n",
      "randperm False\n",
      "range False\n",
      "reciprocal True\n",
      "remainder True\n",
      "renorm True\n",
      "round True\n",
      "rsqrt True\n",
      "saddmm False\n",
      "save False\n",
      "serialization False\n",
      "set_default_tensor_type False\n",
      "set_num_threads False\n",
      "set_printoptions False\n",
      "set_rng_state False\n",
      "sigmoid True\n",
      "sign True\n",
      "sin True\n",
      "sinh True\n",
      "smm False\n",
      "sort True\n",
      "sparse False\n",
      "split True\n",
      "sqrt True\n",
      "squeeze True\n",
      "stack False\n",
      "std True\n",
      "storage True\n",
      "sum True\n",
      "svd True\n",
      "symeig True\n",
      "sys False\n",
      "t True\n",
      "take True\n",
      "tan True\n",
      "tanh True\n",
      "tensor False\n",
      "topk True\n",
      "torch False\n",
      "trace True\n",
      "transpose True\n",
      "tril True\n",
      "triu True\n",
      "trtrs True\n",
      "trunc True\n",
      "typename False\n",
      "unbind False\n",
      "unsqueeze True\n",
      "utils False\n",
      "var True\n",
      "version False\n",
      "zero False\n",
      "zeros False\n",
      "zeros_like False\n"
     ]
    }
   ],
   "source": [
    "for x in dir(torch):\n",
    "    print(x, x in dir(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_workers(worker_ids):\n",
    "    def decorate(func):\n",
    "        def send_to_workers(*args, **kwargs):\n",
    "            command = func(*args, **kwargs)\n",
    "            for worker in worker_ids:\n",
    "                print(\"Placeholder print for sending command to worker {}\".format(worker))\n",
    "                send_command(command)\n",
    "            receive_commands(worker_ids)  ## Probably needs to happen async\n",
    "        return send_to_workers\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def send_command(command):\n",
    "    print(command)\n",
    "    print('===========')\n",
    "    print()\n",
    "\n",
    "def receive_commands(worker_ids):\n",
    "    print('Placeholder print for receiving commands from workers in the following list')\n",
    "    print(worker_ids)\n",
    "    print('For Compute and Tree mode, I think this is a single synchronous listen that terminates whenever the message is received')\n",
    "    print('\\t(I think, though I\\'m still not quite familiar with how Tree works)')\n",
    "    print('For Federated mode, this is an asynchronous listen, one thread to each worker.')\n",
    "    print('\\tTerminates when a stopping criterion is met.')\n",
    "    print('Stopping criterion for synchronous SGD is when each worker has reported in.')\n",
    "    print('Stopping criterion for asynchronous SGD is whenever the client decides to update the model')\n",
    "    print('\\t-- this will require some extra engineering to keep training going smoothlyin the meantime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hook_var()\n",
    "hook_add(['A1', 'A2', 'B1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.FloatTensor([[2,2],[2,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "{'tensor_id': 4983439554, 'command': 'add', 'args': ['self', 'other'], 'varargs': None, 'keywords': None, 'values': [Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ", Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "], 'types': [<class 'torch.autograd.variable.Variable'>, <class 'torch.autograd.variable.Variable'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker A2\n",
      "{'tensor_id': 4983439554, 'command': 'add', 'args': ['self', 'other'], 'varargs': None, 'keywords': None, 'values': [Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ", Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "], 'types': [<class 'torch.autograd.variable.Variable'>, <class 'torch.autograd.variable.Variable'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "{'tensor_id': 4983439554, 'command': 'add', 'args': ['self', 'other'], 'varargs': None, 'keywords': None, 'values': [Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ", Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "], 'types': [<class 'torch.autograd.variable.Variable'>, <class 'torch.autograd.variable.Variable'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'A2', 'B1']\n",
      "For Compute and Tree mode, I think this is a single synchronous listen that terminates whenever the message is received\n",
      "\t(I think, though I'm still not quite familiar with how Tree works)\n",
      "For Federated mode, this is an asynchronous listen, one thread to each worker.\n",
      "\tTerminates when a stopping criterion is met.\n",
      "Stopping criterion for synchronous SGD is when each worker has reported in.\n",
      "Stopping criterion for asynchronous SGD is whenever the client decides to update the model\n",
      "\t-- this will require some extra engineering to keep training going smoothlyin the meantime\n"
     ]
    }
   ],
   "source": [
    "x.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder print for sending command to worker A1\n",
      "{'tensor_id': 4983439554, 'command': '__add__', 'args': ['self', 'other'], 'varargs': None, 'keywords': None, 'values': [Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ", Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "], 'types': [<class 'torch.autograd.variable.Variable'>, <class 'torch.autograd.variable.Variable'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker A2\n",
      "{'tensor_id': 4983439554, 'command': '__add__', 'args': ['self', 'other'], 'varargs': None, 'keywords': None, 'values': [Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ", Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "], 'types': [<class 'torch.autograd.variable.Variable'>, <class 'torch.autograd.variable.Variable'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for sending command to worker B1\n",
      "{'tensor_id': 4983439554, 'command': '__add__', 'args': ['self', 'other'], 'varargs': None, 'keywords': None, 'values': [Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      ", Variable containing:\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 2x2]\n",
      "], 'types': [<class 'torch.autograd.variable.Variable'>, <class 'torch.autograd.variable.Variable'>]}\n",
      "===========\n",
      "\n",
      "Placeholder print for receiving commands from workers in the following list\n",
      "['A1', 'A2', 'B1']\n",
      "For Compute and Tree mode, I think this is a single synchronous listen that terminates whenever the message is received\n",
      "\t(I think, though I'm still not quite familiar with how Tree works)\n",
      "For Federated mode, this is an asynchronous listen, one thread to each worker.\n",
      "\tTerminates when a stopping criterion is met.\n",
      "Stopping criterion for synchronous SGD is when each worker has reported in.\n",
      "Stopping criterion for asynchronous SGD is whenever the client decides to update the model\n",
      "\t-- this will require some extra engineering to keep training going smoothlyin the meantime\n"
     ]
    }
   ],
   "source": [
    "x + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work in progress\n",
    "The following stuff is ideally meant to automate the `hook_var` and `hook_add` functions and their ilk.\n",
    "I've run into some trouble, mainly because there's no trivial way of reproducing some of the stuff above for functions that don't live completely in Python (e.g. functions that are considered 'built-in' because they originate somewhere in C).\n",
    "Once I learn more about the `inspect` module, it may be possible.  To be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_name(func, name):\n",
    "    func.name = name\n",
    "    return func\n",
    "\n",
    "def assign_sig(func, sig_func):\n",
    "    func.sig = inspect.signature(sig_func)\n",
    "    return func\n",
    "\n",
    "def assign_argspec(func, spec_func):\n",
    "    func.spec = inspect.getargspec(spec_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generic(*args, **kwargs):\n",
    "    frame = inspect.currentframe()\n",
    "    command = compile_command(generic.name, frame)\n",
    "    print(command)\n",
    "    #send_command(command, worker)\n",
    "    #receive_command(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = torch.addmm.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no signature found for builtin <built-in function addmm>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-faab8a57b2fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgeneric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_sig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgeneric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-32abe8f63aa5>\u001b[0m in \u001b[0;36massign_sig\u001b[0;34m(func, sig_func)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0massign_sig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openmined/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3034\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openmined/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2784\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0;32m-> 2786\u001b[0;31m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[1;32m   2787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openmined/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m         return _signature_from_builtin(sigcls, obj,\n\u001b[0;32m-> 2265\u001b[0;31m                                        skip_bound_arg=skip_bound_arg)\n\u001b[0m\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/openmined/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36m_signature_from_builtin\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2088\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__text_signature__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2090\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no signature found for builtin {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_fromstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: no signature found for builtin <built-in function addmm>"
     ]
    }
   ],
   "source": [
    "generic = assign_sig(generic, torch.addmm)\n",
    "generic = assign_name(generic, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.autograd.Variable.add = generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.FloatTensor([[2,2],[2,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'command': 'add', 'args': [], 'varargs': 'args', 'keywords': 'kwargs', 'values': [], 'types': []}\n"
     ]
    }
   ],
   "source": [
    "x.add(other = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy(x, y, z = 5):\n",
    "     print(inspect.getargvalues(inspect.currentframe())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "dummy(1, 2, z = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.FloatTensor([1,2,3,4]),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variable'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3\n",
       " 5\n",
       " 7\n",
       " 9\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compile_command() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5ceca8c5cc3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompile_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'add'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: compile_command() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "compile_command('add', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def send_command(command, *args, **kwargs):\n",
    "    assert type(command) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = Var(x), Var(y)\n",
    "a + b != Var(x + y)\n",
    "Variable.__add__ != FloatTensor.__add__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hook_var():\n",
    "    \n",
    "    Variable.lit___add__ = Variable.__add__ \n",
    "    def grid___add__(self,other):\n",
    "        print(\"__add__\")\n",
    "        return self.lit___add__(other)\n",
    "    Variable.__add__ = grid___add__\n",
    "    \n",
    "    Variable.lit_add = Variable.add\n",
    "    def grid_add(self,other):\n",
    "        print(\"add\")\n",
    "        return self.lit_add(other)\n",
    "    Variable.add = grid_add\n",
    "\n",
    "def hook_float():\n",
    "    torch.FloatTensor.lit___add__ = torch.FloatTensor.__add__ \n",
    "    def grid___add__(self,other):\n",
    "        print(\"__add__\")\n",
    "        return self.lit___add__(other)\n",
    "    torch.FloatTensor.__add__ = grid___add__\n",
    "    \n",
    "    torch.FloatTensor.lit_add = torch.FloatTensor.add\n",
    "    def grid_add(self,other):\n",
    "        print(\"add\")\n",
    "        return self.lit_add(other)\n",
    "    torch.FloatTensor.add = grid_add\n",
    "    \n",
    "def hook_torch():\n",
    "    torch.lit_addmm = torch.addmm\n",
    "    def grid_addmm(mat, mat1, mat2, beta=1, alpha=1):\n",
    "        print(\"addmm\")\n",
    "        return torch.addmm(mat, mat1, mat2, beta = beta, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hook_float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.FloatTensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 4\n",
       " 6\n",
       " 8\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__add__\n",
      "add\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 4\n",
       " 6\n",
       " 8\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph():\n",
    "    frames = inspect.stack()\n",
    "    x = Variable(torch.FloatTensor([1,2,3,4]),requires_grad=True)\n",
    "    y = Variable(torch.FloatTensor([2,3,4,5]),requires_grad=True)\n",
    "    z = x.add(y)\n",
    "    z.sum().backward()\n",
    "    return x.grad, y.grad, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.FloatTensor of size 4], Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.FloatTensor of size 4], [FrameInfo(frame=<frame object at 0x7f8b39eac600>, filename='<ipython-input-32-3c1f715c0d0c>', lineno=2, function='graph', code_context=['    frames = inspect.stack()\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x7f8b39ed07c8>, filename='<ipython-input-33-76e6a91db885>', lineno=1, function='<module>', code_context=['graph()\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a59652ca98>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/IPython/core/interactiveshell.py', lineno=2910, function='run_code', code_context=['                exec(code_obj, self.user_global_ns, self.user_ns)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a59652c828>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/IPython/core/interactiveshell.py', lineno=2856, function='run_ast_nodes', code_context=['                if self.run_code(code, result):\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a59652d3c8>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/IPython/core/interactiveshell.py', lineno=2728, function='run_cell', code_context=['                   interactivity=interactivity, compiler=compiler, result=result)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x7f8b39ed5408>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/ipykernel/zmqshell.py', lineno=537, function='run_cell', code_context=['        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a59652d168>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/ipykernel/ipkernel.py', lineno=208, function='do_execute', code_context=['            res = shell.run_cell(code, store_history=store_history, silent=silent)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a596461df8>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/ipykernel/kernelbase.py', lineno=399, function='execute_request', code_context=['                                        user_expressions, allow_stdin)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x7f8b8401d1b8>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/ipykernel/kernelbase.py', lineno=233, function='dispatch_shell', code_context=['                handler(stream, idents, msg)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a5964bd4d8>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/ipykernel/kernelbase.py', lineno=283, function='dispatcher', code_context=['                return self.dispatch_shell(stream, msg)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x7f8b8401b828>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/tornado/stack_context.py', lineno=277, function='null_wrapper', code_context=['                return fn(*args, **kwargs)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a59652cd08>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py', lineno=414, function='_run_callback', code_context=['                callback(*args, **kwargs)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x7f8b840046e8>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py', lineno=472, function='_handle_recv', code_context=['                self._run_callback(callback, msg)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a596472e98>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py', lineno=440, function='_handle_events', code_context=['                self._handle_recv()\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a59652cf48>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/tornado/stack_context.py', lineno=277, function='null_wrapper', code_context=['                return fn(*args, **kwargs)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a595964c88>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/tornado/ioloop.py', lineno=888, function='start', code_context=['                        handler_func(fd_obj, events)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a595962028>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/zmq/eventloop/ioloop.py', lineno=177, function='start', code_context=['            super(ZMQIOLoop, self).start()\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a5951a74c8>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/ipykernel/kernelapp.py', lineno=478, function='start', code_context=['            self.io_loop.start()\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a595819228>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/traitlets/config/application.py', lineno=658, function='launch_instance', code_context=['        app.start()\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a5951d5118>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/site-packages/ipykernel/__main__.py', lineno=3, function='<module>', code_context=['    app.launch_new_instance()\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a5952361e8>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/runpy.py', lineno=85, function='_run_code', code_context=['    exec(code, run_globals)\\n'], index=0),\n",
       "  FrameInfo(frame=<frame object at 0x55a59519f338>, filename='/home/jason/anaconda3/envs/openmined/lib/python3.6/runpy.py', lineno=193, function='_run_module_as_main', code_context=['                     \"__main__\", mod_spec)\\n'], index=0)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notes -- very unstable.\n",
    "# I think some of the things I'm replacing might have decorators, which could lead to some of the weird behavior\n",
    "# We need to hook to these methods so that we can send out commands to workers\n",
    "# Just need to be able to do so reliably\n",
    "# May also need to disable the __str__ or print functionality on variables/tensors to avoid these RuntimeErrors\n",
    "\n",
    "def hook_var():\n",
    "    \n",
    "    # None of the `__init__` or `new` stuff works yet\n",
    "    curse(torch._C._VariableBase, \"old__init__\", torch._C._VariableBase.new)\n",
    "    #curse(Variable, \"old__init__\", Variable.new)\n",
    "    def _new___init__(self, *args):\n",
    "        self.id = 1\n",
    "        self.data_addr = 2\n",
    "        print(\"init\")\n",
    "        #return self.old__init__(*args)\n",
    "    #curse(torch._C._VariableBase, \"__init__\", _new___init__)\n",
    "    curse(torch._C._VariableBase, \"new\", _new___init__)\n",
    "    \n",
    "    # `add` and `__add__` work sometimes, and even then not as expected\n",
    "    curse(Variable, \"old__add__\", Variable.__add__)\n",
    "    def _new___add__(self, other):\n",
    "        print(\"__add__\")\n",
    "        #return self.old__add__(other)\n",
    "    curse(Variable, \"__add__\", _new___add__)\n",
    "   \n",
    "    curse(torch._C._VariableBase, 'old_add', torch._C._VariableBase.add)\n",
    "    def _new_add(self, other):\n",
    "        print(\"add\")\n",
    "        #return self.old_add(other)\n",
    "    curse(Variable, 'add', _new_add)\n",
    "    \n",
    "    # This works, usually\n",
    "    torch.old_addmm = torch.addmm\n",
    "    def _new_addmm(mat, mat1, mat2, beta=1, alpha=1):\n",
    "        print(\"addmm\")\n",
    "        #return torch.old_addmm(beta, mat, alpha, mat1, mat2)\n",
    "    torch.addmm = _new_addmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hook_torch():\n",
    "    torch.tensor = grid_tensor\n",
    "    torch.zeros = grid_zeros\n",
    "    hook_var()\n",
    "\n",
    "    \n",
    "    #hook_long()\n",
    "\n",
    "    # anything else we need to do to modify/override torch for the Client globally\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hook_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2]\n",
      "None\n",
      "None\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2,2], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-278dfd41be8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "x.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, include_footer)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_matrix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_matrix_str\u001b[0;34m(self, indent, formatter, force_truncate)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformatter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         fmt, scale, sz = _number_format(self,\n\u001b[0;32m--> 215\u001b[0;31m                                         min_sz=5 if not print_full_mat else 0)\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# TODO: use fmod?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mint_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, include_footer)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_matrix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_matrix_str\u001b[0;34m(self, indent, formatter, force_truncate)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformatter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         fmt, scale, sz = _number_format(self,\n\u001b[0;32m--> 215\u001b[0;31m                                         min_sz=5 if not print_full_mat else 0)\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# TODO: use fmod?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mint_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "x.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, include_footer)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_matrix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_matrix_str\u001b[0;34m(self, indent, formatter, force_truncate)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformatter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         fmt, scale, sz = _number_format(self,\n\u001b[0;32m--> 215\u001b[0;31m                                         min_sz=5 if not print_full_mat else 0)\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# TODO: use fmod?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mint_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addmm\n"
     ]
    }
   ],
   "source": [
    "torch.addmm(x, x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below doesn't work -- can't subclass FloatTensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# torch.tensor(data, dtype=None, device=None, requires_grad=False)\n",
    "# torch.zeros(shape, dtype=None, device=None, requires_grad=False)\n",
    "# torch.ones(...)\n",
    "# torch.empty(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FakeVar(torch.autograd.variable):\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        return self.add(other)\n",
    "    \n",
    "    def add(self, other):\n",
    "        print(\"add\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch._C._VariableBase = FakeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.autograd.Variable = FakeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "torch.float32\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor((2,2), dtype = torch.float, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__add__\n",
      "__add__\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Overflow when unpacking long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# characters to replace unicode characters with.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self, include_footer)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vector_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_matrix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mstrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_matrix_str\u001b[0;34m(self, indent, formatter, force_truncate)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformatter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         fmt, scale, sz = _number_format(self,\n\u001b[0;32m--> 215\u001b[0;31m                                         min_sz=5 if not print_full_mat else 0)\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_number_format\u001b[0;34m(tensor, min_sz)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# TODO: use fmod?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mint_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Overflow when unpacking long"
     ]
    }
   ],
   "source": [
    "a.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.variable.Variable"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "None\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.autograd.variable.Variable"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.tensor((2,2), requires_grad = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3.1621e-28  9.1370e-41\n",
       " 3.1621e-28  9.1370e-41\n",
       "[torch.FloatTensor of size (2,2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openmined]",
   "language": "python",
   "name": "conda-env-openmined-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
